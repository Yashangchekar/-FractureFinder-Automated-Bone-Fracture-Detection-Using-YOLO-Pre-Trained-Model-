{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36e203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18120424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ec889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvzone\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2586fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1a6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames: ['elbow positive', 'fingers positive', 'forearm fracture', 'humerus fracture', 'humerus', 'shoulder fracture', 'wrist positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cfbdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 elbow positive, 223.6ms\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'xyxy'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (tuple): Original image shape in (height, width) format.\n        boxes (Boxes, optional): Object containing detection bounding boxes.\n        masks (Masks, optional): Object containing detection masks.\n        probs (Probs, optional): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints, optional): Object containing detected keypoints for each object.\n        speed (dict): Dictionary of preprocess, inference, and postprocess speeds (ms/image).\n        names (dict): Dictionary of class names.\n        path (str): Path to the image file.\n\n    Methods:\n        update(boxes=None, masks=None, probs=None, obb=None): Updates object attributes with new detection results.\n        cpu(): Returns a copy of the Results object with all tensors on CPU memory.\n        numpy(): Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda(): Returns a copy of the Results object with all tensors on GPU memory.\n        to(*args, **kwargs): Returns a copy of the Results object with tensors on a specified device and dtype.\n        new(): Returns a new Results object with the same image, path, and names.\n        plot(...): Plots detection results on an input image, returning an annotated image.\n        show(): Show annotated results to screen.\n        save(filename): Save annotated results to file.\n        verbose(): Returns a log string for each task, detailing detections and classifications.\n        save_txt(txt_file, save_conf=False): Saves detection results to a text file.\n        save_crop(save_dir, file_name=Path(\"im.jpg\")): Saves cropped detection images.\n        tojson(normalize=False): Converts detection results to JSON format.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Loop through detection results\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detection_result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m detection_result\u001b[38;5;241m.\u001b[39mxyxy[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# Extract box coordinates\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(box[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(box[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mint\u001b[39m(box[\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;28mint\u001b[39m(box[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m     12\u001b[0m         w, h \u001b[38;5;241m=\u001b[39m x2 \u001b[38;5;241m-\u001b[39m x1, y2 \u001b[38;5;241m-\u001b[39m y1\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\__init__.py:156\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Results' object has no attribute 'xyxy'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (tuple): Original image shape in (height, width) format.\n        boxes (Boxes, optional): Object containing detection bounding boxes.\n        masks (Masks, optional): Object containing detection masks.\n        probs (Probs, optional): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints, optional): Object containing detected keypoints for each object.\n        speed (dict): Dictionary of preprocess, inference, and postprocess speeds (ms/image).\n        names (dict): Dictionary of class names.\n        path (str): Path to the image file.\n\n    Methods:\n        update(boxes=None, masks=None, probs=None, obb=None): Updates object attributes with new detection results.\n        cpu(): Returns a copy of the Results object with all tensors on CPU memory.\n        numpy(): Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda(): Returns a copy of the Results object with all tensors on GPU memory.\n        to(*args, **kwargs): Returns a copy of the Results object with tensors on a specified device and dtype.\n        new(): Returns a new Results object with the same image, path, and names.\n        plot(...): Plots detection results on an input image, returning an annotated image.\n        show(): Show annotated results to screen.\n        save(filename): Save annotated results to file.\n        verbose(): Returns a log string for each task, detailing detections and classifications.\n        save_txt(txt_file, save_conf=False): Saves detection results to a text file.\n        save_crop(save_dir, file_name=Path(\"im.jpg\")): Saves cropped detection images.\n        tojson(normalize=False): Converts detection results to JSON format.\n    "
     ]
    }
   ],
   "source": [
    "# # Read the image\n",
    "# img = cv2.imread(\"pp.jpg\")\n",
    "\n",
    "# # Perform object detection\n",
    "# results = model(img, stream=True)\n",
    "\n",
    "# # Loop through detection results\n",
    "# for detection_result in results:\n",
    "#     for box in detection_result.xyxy[0]:\n",
    "#         # Extract box coordinates\n",
    "#         x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "#         w, h = x2 - x1, y2 - y1\n",
    "\n",
    "#         # Plot bounding box\n",
    "#         cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "#         # Calculate confidence\n",
    "#         conf = round(float(box[4]), 2)\n",
    "\n",
    "#         # Get class index\n",
    "#         cls = int(box[5])\n",
    "\n",
    "#         # Plot class name and confidence\n",
    "#         cv2.putText(img, f'{classNames[cls]} {conf}', (max(0, x1), max(35, y1)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                     0.7, (0, 0, 255), 2)\n",
    "# # \n",
    "# # Display result\n",
    "# cv2.imshow(\"image\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8baa7fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\yash\\Documents\\YOLO1\\bone_defect\\bone_dataset\\pp.jpg: 640x640 1 elbow positive, 104.0ms\n",
      "Speed: 5.0ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Define class names (modify these based on your model's classes)\n",
    "classNames = ['elbow positive', 'fingers positive', 'forearm fracture', 'humerus fracture', 'humerus', 'shoulder fracture', 'wrist positive']\n",
    "\n",
    "\n",
    "\n",
    "# Load the YOLO model (assuming 'best.pt' is your model file)\n",
    "model = YOLO(\"best.pt\")\n",
    "results=model('pp.jpg',show=True)\n",
    "cv2.waitKey(0)                  #time-millisecond\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935ddd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29decb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
